-- Test push join below union all feature
--
-- Generation of join below union all alternative can be verified
-- using GUC optimizer_print_xform_results
--
-- This alternative is generated for all queries in this suite, 
-- except for the join of two union all test, and cte test
-- 
-- ORCA's cost model determines whether to choose this alternative
--
-- Intuitively, join below union is desirable when (1) the union all
-- children can benefit from physical join options not available 
-- after the union all operation, such as indexed nested loop join;
-- and (2) the cost of scanning the non-union all side is relatively
-- low, such as a small table size, and existing distribution or
-- duplication  
--
-- This is an ORCA feature. The plan shape is only verified for ORCA
-- plans. Correctness of the plans can be verified by the # of output
-- rows
-- start_ignore
drop schema if exists join_union_all cascade;
NOTICE:  schema "join_union_all" does not exist, skipping
-- end_ignore
-- greenplum
create schema join_union_all;
set search_path=join_union_all;
set optimizer_trace_fallback=on;
-- GUC
set optimizer_enable_push_join_below_union_all=on; -- default off
-- distributed, 1 column, 1k rows
create table dist_small_1(c1 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into dist_small_1 select generate_series(1,1000);
-- distributed, 1 column, 1k rows
create table dist_small_2(c1 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into dist_small_2 select generate_series(1,1000);
-- distributed, 1 column, 100k rows
create table dist_large_1(c1 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into dist_large_1 select generate_series(1,100000);
-- distributed, 1 column, 100k rows
create table dist_large_2(c1 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into dist_large_2 select generate_series(1,100000);
-- distributed, 1 column, 100k rows
create table dist_large_ao(c1 int) with (appendonly=true);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into dist_large_ao select generate_series(1,100000);
-- distributed, 1 column, char(4), 1k rows
create table char_small_1(c1 char(4));
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into char_small_1 select generate_series(1,1000);
-- distributed, 1 column, char(3), 100 rows
create table char_small_2(c1 char(3));
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into char_small_2 select generate_series(1,100);
-- distributed, 0 rows
-- this is to minimize the cost of scanning inner_1 multiple times,
-- as needed by this test suite to demonstrate the join below union
-- all alternative
create table inner_1(cc int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'cc' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
-- randomly, 10 rows
create table inner_2(cc int) distributed randomly;
insert into inner_2 select generate_series(1,10);
-- distributed, 0 rows
create table inner_3(cc varchar);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'cc' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
-- partition table, 2 columns, 100k rows, join on partition key
CREATE TABLE part (c1 int, c2 int) partition by list(c2) (
partition part1 VALUES (1, 2, 3, 4), 
partition part2 VALUES (5, 6, 7), 
partition part3 VALUES (8, 9, 0));
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
NOTICE:  CREATE TABLE will create partition "part_1_prt_part1" for table "part"
NOTICE:  CREATE TABLE will create partition "part_1_prt_part2" for table "part"
NOTICE:  CREATE TABLE will create partition "part_1_prt_part3" for table "part"
INSERT INTO part SELECT i, i%10 FROM generate_series(1, 100000) i;
-- distribution table, 2 columns, 100k rows, join on distribution key
CREATE TABLE dist (c1 int, c2 int) distributed by (c2);
INSERT INTO dist SELECT i, i FROM generate_series(1, 100000) i;
-- randomly distributed table, 2 columns, 100k rows
CREATE TABLE rand (c1 int, c2 int) distributed randomly;
INSERT INTO rand SELECT i, i FROM generate_series(1, 100000) i;
-- built index for dist_small_1 and dist_large_1,
-- but not for dist_small_2 or dist_large_2 (yet)
create index dist_small_1_index on dist_small_1 using btree (c1);
create index dist_large_1_index on dist_large_1 using btree (c1);
-- build index for char_small_1
-- but not for char_small_2
create index char_small_1_index on char_small_1 using btree (c1);
-- build index for dist and rand
-- but not for part
create index dist_index on dist using btree (c2);
create index rand_index on rand using btree (c2);
-- analyze
analyze dist_small_1;
analyze dist_small_2;
analyze dist_large_1;
analyze dist_large_2;
analyze dist_large_ao;
analyze char_small_1;
analyze char_small_2;
analyze inner_1;
analyze inner_2;
analyze inner_3;
analyze part;
analyze dist;
analyze rand;
-- view
create view dist_view_small as
select c1 from dist_small_1 union all
select c1 from dist_small_2;
create view dist_view_large as
select c1 from dist_large_1 union all
select c1 from dist_large_2;
create view dist_view_large_uniq as
select c1 from dist_large_1 union
select c1 from dist_large_2;
create view dist_view_large_filter as
select c1 from dist_large_1 where c1 < 90000 union all
select c1 from dist_large_2;
create view dist_view_large_subquery as
select c1 from dist_large_1 where c1 = (select count() from dist_small_1) union all
select c1 from dist_large_2;
create view dist_view_large_ao as
select c1 from dist_large_1 union all
select c1 from dist_large_ao;
create view dist_view_join as
select dist_small_1.c1 from dist_small_1 join dist_small_2
 on dist_small_1.c1 = dist_small_2.c1 union all
select c1 from dist_large_1; 
create view char_view_small as
select c1 from char_small_1 union all
select c1 from char_small_2;
create view part_dist_rand as
select * from part union all
select * from dist union all
select * from rand;
create view part_dist as
select * from part union all
select * from dist;
create view part_dist_filter as
select * from part where c1 < 100 and c2 in (1, 5, 8) union all
select * from dist where c1 < 90000 and c2 > 90000;
create view part_rand as
select * from part union all
select * from rand;
-- equality join predicate 
-- union all of small tables
-- join below union all alternative generated, but not chosen
-- Intuition: Hash join with small outer child is cheaper than
-- pushing join condition down as the index condition
explain analyze select c1 from dist_view_small join inner_1 on c1 = cc;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..54.62 rows=11 width=4) (actual time=5.322..5.322 rows=0 loops=1)
   ->  Hash Join  (cost=1.01..54.62 rows=4 width=4) (never executed)
         Hash Cond: (dist_small_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..26.00 rows=667 width=4) (actual time=0.028..0.028 rows=1 loops=1)
               ->  Seq Scan on dist_small_1  (cost=0.00..13.00 rows=334 width=4) (actual time=0.028..0.028 rows=1 loops=1)
               ->  Seq Scan on dist_small_2  (cost=0.00..13.00 rows=334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.775 ms
   (slice0)    Executor memory: 90K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 6.508 ms
(14 rows)

-- inequality join predicate 
-- union all of small tables
-- join below union all alternative chosen
-- Intuition: Compared to the query above, hash join is not an option
-- due to the inequality join condition. This time, join is pushed 
-- below union all to leverage indexed nested loop join.
explain analyze select c1 from dist_view_small join inner_1 on c1 < cc;
                                                                 QUERY PLAN                                                                 
--------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=10000000000.00..10000000127.05 rows=667 width=4) (actual time=5.572..5.572 rows=0 loops=1)
   ->  Nested Loop  (cost=10000000000.00..10000000127.05 rows=223 width=4) (never executed)
         Join Filter: (dist_small_1.c1 < inner_1.cc)
         ->  Append  (cost=0.00..26.00 rows=667 width=4) (actual time=0.008..0.180 rows=680 loops=1)
               ->  Seq Scan on dist_small_1  (cost=0.00..13.00 rows=334 width=4) (actual time=0.008..0.048 rows=340 loops=1)
               ->  Seq Scan on dist_small_2  (cost=0.00..13.00 rows=334 width=4) (actual time=0.009..0.063 rows=340 loops=1)
         ->  Materialize  (cost=0.00..1.05 rows=1 width=4) (never executed)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                     ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 10.698 ms
   (slice0)    Executor memory: 123K bytes.
   (slice1)    Executor memory: 52K bytes avg x 3 workers, 58K bytes max (seg1).
   (slice2)    Executor memory: 92K bytes avg x 3 workers, 92K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 35.599 ms
(16 rows)

-- union all of large tables
-- join below union all alternative chosen
-- Intuition: pushing join condition down as the index condition
-- is cheaper than hash join with large outer child.
explain analyze select c1 from dist_view_large join inner_1 on c1 = cc;
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..4975.01 rows=200 width=4) (actual time=4.626..4.626 rows=0 loops=1)
   ->  Hash Join  (cost=1.01..4975.01 rows=67 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (actual time=0.016..0.016 rows=1 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.016..0.016 rows=1 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.448 ms
   (slice0)    Executor memory: 90K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 5.733 ms
(14 rows)

-- union all of large tables
-- join below union all alternative generated, but not chosen
-- Intuition: Compared to the query above, join's inner child is larger,
-- which has two implications. One, the cost of indexed nested loop join
-- becomes higher. Two, the cost of scanning the inner side twice is
-- higher. Both factors led ORCA to not push join below union all. 
explain analyze select c1 from dist_view_large join inner_2 on c1 = cc;
                                                                  QUERY PLAN                                                                  
----------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=3.43..4995.43 rows=2000 width=4) (actual time=38.768..40.150 rows=20 loops=1)
   ->  Hash Join  (cost=3.43..4995.43 rows=667 width=4) (actual time=2.944..39.260 rows=10 loops=1)
         Hash Cond: (dist_large_1.c1 = inner_2.cc)
         Extra Text: (seg0)   Hash chain length 1.0 avg, 1 max, using 5 of 524288 buckets.
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (actual time=0.017..20.809 rows=66924 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.017..4.038 rows=33462 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.013..3.836 rows=33462 loops=1)
         ->  Hash  (cost=3.30..3.30 rows=4 width=4) (actual time=0.739..0.739 rows=5 loops=1)
               ->  Redistribute Motion 3:3  (slice1; segments: 3)  (cost=0.00..3.30 rows=4 width=4) (actual time=0.568..0.726 rows=5 loops=1)
                     Hash Key: inner_2.cc
                     ->  Seq Scan on inner_2  (cost=0.00..3.10 rows=4 width=4) (actual time=0.026..0.026 rows=5 loops=1)
 Planning time: 1.383 ms
   (slice0)    Executor memory: 127K bytes.
   (slice1)    Executor memory: 42K bytes avg x 3 workers, 42K bytes max (seg0).
   (slice2)    Executor memory: 4172K bytes avg x 3 workers, 4172K bytes max (seg0).  Work_mem: 1K bytes max.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 41.203 ms
(18 rows)

-- equality join predicate
-- union all of large tables, one with a filter
-- join below union all alternative generated, but not chosen
explain analyze select c1 from dist_view_large_filter join inner_1 on c1 = cc;
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..5987.62 rows=191 width=4) (actual time=4.763..4.763 rows=0 loops=1)
   ->  Hash Join  (cost=1.01..5987.62 rows=64 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..3372.09 rows=63337 width=4) (actual time=0.020..0.020 rows=1 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1361.00 rows=30003 width=4) (actual time=0.020..0.020 rows=1 loops=1)
                     Filter: (c1 < 90000)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.442 ms
   (slice0)    Executor memory: 123K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 6.171 ms
(15 rows)

-- inequality join predicate
-- union all of large tables, one with a filter
-- join below union all alternative chosen
-- Intuition: Again, once the hash join option is ruled out by the inequality
-- join condition, join is more likely to be pushed down to take advantage of
-- indexed nested loop join.
explain analyze select c1 from dist_view_large_filter join inner_1 on c1 < cc;
                                                                   QUERY PLAN                                                                   
------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=10000000000.00..10000012873.58 rows=63337 width=4) (actual time=43.560..43.560 rows=0 loops=1)
   ->  Nested Loop  (cost=10000000000.00..10000012873.58 rows=21113 width=4) (never executed)
         Join Filter: (dist_large_1.c1 < inner_1.cc)
         ->  Append  (cost=0.00..3372.09 rows=63337 width=4) (actual time=0.019..25.140 rows=63634 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1361.00 rows=30003 width=4) (actual time=0.019..8.741 rows=30172 loops=1)
                     Filter: (c1 < 90000)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.011..4.025 rows=33462 loops=1)
         ->  Materialize  (cost=0.00..1.05 rows=1 width=4) (never executed)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                     ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 0.998 ms
   (slice0)    Executor memory: 123K bytes.
   (slice1)    Executor memory: 42K bytes avg x 3 workers, 42K bytes max (seg0).
   (slice2)    Executor memory: 92K bytes avg x 3 workers, 92K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 44.805 ms
(17 rows)

-- equality join predicate
-- union all of large tables, one child's filter is a subquery
-- join below union all alternative generated, but not chosen
explain analyze select c1 from dist_view_large_subquery join inner_1 on c1 = cc;
                                                                       QUERY PLAN                                                                       
--------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=16.75..2703.79 rows=101 width=4) (actual time=3.034..3.034 rows=0 loops=1)
   ->  Hash Join  (cost=16.75..2703.79 rows=34 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=15.74..1326.77 rows=33334 width=4) (never executed)
               ->  Index Only Scan using dist_large_1_index on dist_large_1  (cost=15.74..215.76 rows=1 width=4) (never executed)
                     Index Cond: (c1 = $0)
                     Heap Fetches: 0
                     InitPlan 1 (returns $0)  (slice3)
                       ->  Aggregate  (cost=15.56..15.57 rows=1 width=8) (actual time=1.672..0.000 rows=1 loops=1)
                             ->  Gather Motion 3:1  (slice1; segments: 3)  (cost=15.50..15.55 rows=1 width=8) (actual time=1.246..0.000 rows=3 loops=1)
                                   ->  Aggregate  (cost=15.50..15.51 rows=1 width=8) (actual time=0.102..0.102 rows=1 loops=1)
                                         ->  Seq Scan on dist_small_1  (cost=0.00..13.00 rows=334 width=0) (actual time=0.008..0.080 rows=340 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.804 ms
   (slice0)    Executor memory: 284K bytes.
 _ (slice1)    Workers: Workers: 3 not dispatched;.  
 Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 4204K bytes avg x 3 workers, 4204K bytes max (seg0).
   (slice3)    Executor memory: 156K bytes.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 6.762 ms
(24 rows)

-- inequality join predicate
-- union all of large tables, one child's filter is a subquery
-- join below union all alternative generated, but not chosen
explain analyze select c1 from dist_view_large_subquery join inner_1 on c1 < cc;
                                                                        QUERY PLAN                                                                         
-----------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)  (cost=10000000015.74..10000006327.87 rows=33334 width=4) (actual time=17.162..17.162 rows=0 loops=1)
   ->  Nested Loop  (cost=10000000015.74..10000006327.87 rows=11112 width=4) (never executed)
         Join Filter: (dist_large_1.c1 < inner_1.cc)
         ->  Append  (cost=15.74..1326.77 rows=33334 width=4) (actual time=0.655..8.389 rows=33463 loops=1)
               ->  Index Only Scan using dist_large_1_index on dist_large_1  (cost=15.74..215.76 rows=1 width=4) (actual time=0.655..0.657 rows=1 loops=1)
                     Index Cond: (c1 = $0)
                     Heap Fetches: 0
                     InitPlan 1 (returns $0)  (slice4)
                       ->  Aggregate  (cost=15.56..15.57 rows=1 width=8) (actual time=0.668..0.000 rows=1 loops=1)
                             ->  Gather Motion 3:1  (slice1; segments: 3)  (cost=15.50..15.55 rows=1 width=8) (actual time=0.575..0.000 rows=3 loops=1)
                                   ->  Aggregate  (cost=15.50..15.51 rows=1 width=8) (actual time=0.098..0.098 rows=1 loops=1)
                                         ->  Seq Scan on dist_small_1  (cost=0.00..13.00 rows=334 width=0) (actual time=0.009..0.062 rows=340 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.016..4.297 rows=33462 loops=1)
         ->  Materialize  (cost=0.00..1.05 rows=1 width=4) (never executed)
               ->  Broadcast Motion 3:3  (slice2; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                     ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.396 ms
   (slice0)    Executor memory: 288K bytes.
 _ (slice1)    Workers: Workers: 3 not dispatched;.  
 Executor memory: 44K bytes avg x 3 workers, 44K bytes max (seg0).
   (slice2)    Executor memory: 60K bytes avg x 3 workers, 60K bytes max (seg0).
   (slice3)    Executor memory: 192K bytes avg x 3 workers, 192K bytes max (seg0).
   (slice4)    Executor memory: 160K bytes.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 19.890 ms
(26 rows)

-- union all of large tables, one is append only 
-- join below union all alternative chosen
explain analyze select c1 from dist_view_large_ao join inner_1 on c1 = cc;
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..4895.01 rows=200 width=4) (actual time=3.367..3.367 rows=0 loops=1)
   ->  Hash Join  (cost=1.01..4895.01 rows=67 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..2142.00 rows=66667 width=4) (actual time=0.012..0.012 rows=1 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.012..0.012 rows=1 loops=1)
               ->  Seq Scan on dist_large_ao  (cost=0.00..1031.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.180 ms
   (slice0)    Executor memory: 106K bytes.
   (slice1)    Executor memory: 4186K bytes avg x 3 workers, 4186K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 4.652 ms
(14 rows)

-- union all of a join and table
-- join below union all alternative chosen
explain analyze select c1 from dist_view_join join inner_1 on c1 = cc;
                                                         QUERY PLAN                                                         
----------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=26.51..2564.02 rows=101 width=4) (actual time=2.659..2.659 rows=0 loops=1)
   ->  Hash Join  (cost=26.51..2564.02 rows=34 width=4) (never executed)
         Hash Cond: (dist_small_1.c1 = inner_1.cc)
         ->  Append  (cost=25.50..1173.25 rows=33667 width=4) (never executed)
               ->  Hash Join  (cost=25.50..52.25 rows=334 width=4) (never executed)
                     Hash Cond: (dist_small_1.c1 = dist_small_2.c1)
                     ->  Seq Scan on dist_small_1  (cost=0.00..13.00 rows=334 width=4) (never executed)
                     ->  Hash  (cost=13.00..13.00 rows=334 width=4) (never executed)
                           ->  Seq Scan on dist_small_2  (cost=0.00..13.00 rows=334 width=4) (never executed)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.832 ms
   (slice0)    Executor memory: 123K bytes.
   (slice1)    Executor memory: 2186K bytes avg x 3 workers, 2186K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 4.483 ms
(18 rows)

-- subquery: union all
-- join below union all alternative chosen
explain analyze select c1 from (select c1 from dist_large_1 union all
select c1 from dist_large_2) as inline join inner_1 on c1 = cc;
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..4975.01 rows=200 width=4) (actual time=4.365..4.365 rows=0 loops=1)
   ->  Hash Join  (cost=1.01..4975.01 rows=67 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (actual time=0.015..0.015 rows=1 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.015..0.015 rows=1 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 0.973 ms
   (slice0)    Executor memory: 90K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 5.412 ms
(14 rows)

-- subquery: aggregation
-- join below union all alternative chosen
explain analyze select c1 from dist_view_large join
 (select distinct cc from inner_1) as inline on c1 = cc;
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.03..4975.03 rows=200 width=4) (actual time=2.026..2.026 rows=0 loops=1)
   ->  Hash Join  (cost=1.03..4975.03 rows=67 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (actual time=0.017..0.017 rows=1 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.016..0.016 rows=1 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.02..1.02 rows=1 width=4) (never executed)
               ->  HashAggregate  (cost=1.00..1.01 rows=1 width=4) (never executed)
                     Group Key: inner_1.cc
                     ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.307 ms
   (slice0)    Executor memory: 123K bytes.
   (slice1)    Executor memory: 2138K bytes avg x 3 workers, 2138K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 3.435 ms
(16 rows)

-- subquery: join, equality predicate
-- join below union all alternative chosen, after join order switch
explain analyze select c1 from dist_view_large join
 (select inner_2.cc from inner_1 join inner_2 on inner_1.cc = inner_2.cc) as inline on c1 = cc;
                                                             QUERY PLAN                                                             
------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)  (cost=4.36..4976.43 rows=8 width=4) (actual time=9.047..9.047 rows=0 loops=1)
   ->  Hash Join  (cost=4.36..4976.43 rows=3 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (never executed)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=4.31..4.31 rows=2 width=8) (never executed)
               ->  Redistribute Motion 3:3  (slice2; segments: 3)  (cost=1.08..4.31 rows=2 width=8) (never executed)
                     Hash Key: inner_1.cc
                     ->  Hash Join  (cost=1.08..4.25 rows=2 width=8) (never executed)
                           Hash Cond: (inner_2.cc = inner_1.cc)
                           ->  Seq Scan on inner_2  (cost=0.00..3.10 rows=4 width=4) (never executed)
                           ->  Hash  (cost=1.04..1.04 rows=1 width=4) (never executed)
                                 ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                                       ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 2.328 ms
   (slice0)    Executor memory: 127K bytes.
   (slice1)    Executor memory: 60K bytes avg x 3 workers, 60K bytes max (seg0).
   (slice2)    Executor memory: 2124K bytes avg x 3 workers, 2124K bytes max (seg0).
   (slice3)    Executor memory: 2124K bytes avg x 3 workers, 2124K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 27.743 ms
(23 rows)

-- subquery: join, inequality predicate
-- join below union all alternative generated, but not chosen
explain analyze select c1 from dist_view_large join
 (select inner_2.cc from inner_1 join inner_2 on inner_1.cc < inner_2.cc) as inline on c1 = cc;
                                                                 QUERY PLAN                                                                 
--------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)  (cost=10000000004.72..10000004980.61 rows=223 width=4) (actual time=4.285..4.285 rows=0 loops=1)
   ->  Hash Join  (cost=10000000004.72..10000004980.61 rows=75 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_2.cc)
         Join Filter: (inner_1.cc < dist_large_1.c1)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (never executed)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=10000000004.68..10000000004.68 rows=2 width=8) (never executed)
               ->  Redistribute Motion 3:3  (slice2; segments: 3)  (cost=10000000000.00..10000000004.68 rows=2 width=8) (never executed)
                     Hash Key: inner_2.cc
                     ->  Nested Loop  (cost=10000000000.00..10000000004.61 rows=2 width=8) (never executed)
                           Join Filter: (inner_1.cc < inner_2.cc)
                           ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                                 ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
                           ->  Materialize  (cost=0.00..3.15 rows=4 width=4) (never executed)
                                 ->  Seq Scan on inner_2  (cost=0.00..3.10 rows=4 width=4) (never executed)
 Planning time: 1.737 ms
   (slice0)    Executor memory: 156K bytes.
   (slice1)    Executor memory: 60K bytes avg x 3 workers, 60K bytes max (seg0).
   (slice2)    Executor memory: 60K bytes avg x 3 workers, 60K bytes max (seg0).
   (slice3)    Executor memory: 2124K bytes avg x 3 workers, 2124K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 5.466 ms
(24 rows)

-- left join: union all of large tables
-- join below union all alternative chosen
explain analyze select c1 from inner_1 left join dist_view_large on c1 = cc;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..4975.01 rows=200 width=4) (actual time=3.307..3.307 rows=0 loops=1)
   ->  Hash Right Join  (cost=1.01..4975.01 rows=67 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (never executed)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.289 ms
   (slice0)    Executor memory: 90K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 4.506 ms
(14 rows)

-- right join: union all of large tables
-- join below union all alternative chosen
explain analyze select c1 from dist_view_large right join inner_1 on c1 = cc;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..4975.01 rows=200 width=4) (actual time=4.437..4.437 rows=0 loops=1)
   ->  Hash Right Join  (cost=1.01..4975.01 rows=67 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (never executed)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.295 ms
   (slice0)    Executor memory: 90K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 5.466 ms
(14 rows)

-- union all joined with union
-- join below union all alternative generated, but not chosen
explain analyze select dist_view_large.c1 from dist_view_large
 join dist_view_large_uniq on dist_view_large.c1 = dist_view_large_uniq.c1;
                                                                                    QUERY PLAN                                                                                    
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=11222.00..5415944.00 rows=40000000 width=4) (actual time=72.549..215.379 rows=200000 loops=1)
   ->  Hash Join  (cost=11222.00..5415944.00 rows=13333334 width=4) (actual time=70.932..200.880 rows=66924 loops=1)
         Hash Cond: (dist_large_1.c1 = dist_large_1_1.c1)
         Extra Text: (seg0)   Hash chain length 1.1 avg, 4 max, using 31436 of 262144 buckets.Hash chain length 1.3 avg, 6 max, using 26306 of 65536 buckets; total 0 expansions.
 
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (actual time=0.016..65.719 rows=66924 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.015..11.603 rows=33462 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.016..5.328 rows=33462 loops=1)
         ->  Hash  (cost=8722.00..8722.00 rows=66667 width=4) (actual time=70.827..70.827 rows=33462 loops=1)
               ->  HashAggregate  (cost=4722.00..6722.00 rows=66667 width=4) (actual time=54.618..60.985 rows=33462 loops=1)
                     Group Key: dist_large_1_1.c1
                     Extra Text: (seg0)   Hash chain length 1.3 avg, 6 max, using 26306 of 65536 buckets; total 0 expansions.
 
                     ->  Redistribute Motion 3:3  (slice1; segments: 3)  (cost=0.00..4222.00 rows=66667 width=4) (actual time=2.012..30.529 rows=66924 loops=1)
                           Hash Key: dist_large_1_1.c1
                           ->  Append  (cost=0.00..4222.00 rows=66667 width=4) (actual time=0.033..17.679 rows=66924 loops=1)
                                 ->  Seq Scan on dist_large_1 dist_large_1_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.033..5.274 rows=33462 loops=1)
                                 ->  Seq Scan on dist_large_2 dist_large_2_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.025..5.012 rows=33462 loops=1)
 Planning time: 1.674 ms
   (slice0)    Executor memory: 247K bytes.
   (slice1)    Executor memory: 75K bytes avg x 3 workers, 75K bytes max (seg0).
   (slice2)    Executor memory: 6417K bytes avg x 3 workers, 6417K bytes max (seg0).  Work_mem: 785K bytes max.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 227.843 ms
(25 rows)

-- union all joined with union all
-- ORCA_FEATURE_NOT_SUPPORTED: push join below TWO union all
explain analyze select dist_view_small.c1 from dist_view_small
 join dist_view_large on dist_view_small.c1 = dist_view_large.c1;
                                                             QUERY PLAN                                                             
------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=71.00..58793.00 rows=400000 width=4) (actual time=3.192..45.684 rows=4000 loops=1)
   ->  Hash Join  (cost=71.00..58793.00 rows=133334 width=4) (actual time=0.738..42.020 rows=1360 loops=1)
         Hash Cond: (dist_large_1.c1 = dist_small_1.c1)
         Extra Text: (seg2)   Hash chain length 2.0 avg, 2 max, using 340 of 524288 buckets.
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (actual time=0.020..24.059 rows=66924 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.020..5.231 rows=33462 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.020..11.000 rows=33462 loops=1)
         ->  Hash  (cost=46.00..46.00 rows=667 width=4) (actual time=0.480..0.480 rows=680 loops=1)
               ->  Append  (cost=0.00..26.00 rows=667 width=4) (actual time=0.008..0.205 rows=680 loops=1)
                     ->  Seq Scan on dist_small_1  (cost=0.00..13.00 rows=334 width=4) (actual time=0.008..0.056 rows=340 loops=1)
                     ->  Seq Scan on dist_small_2  (cost=0.00..13.00 rows=334 width=4) (actual time=0.007..0.073 rows=340 loops=1)
 Planning time: 1.903 ms
   (slice0)    Executor memory: 247K bytes.
   (slice1)    Executor memory: 4234K bytes avg x 3 workers, 4234K bytes max (seg0).  Work_mem: 16K bytes max.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 47.218 ms
(17 rows)

-- cte: union all of large tables
-- join below union all alternative chosen
explain analyze with cte as (select c1 from dist_large_1 union all
 select c1 from dist_large_2) select c1 from cte join inner_1 on c1 = cc;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..4753.01 rows=200 width=4) (actual time=2.897..2.897 rows=0 loops=1)
   ->  Hash Join  (cost=1.01..4753.01 rows=67 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (never executed)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.083 ms
   (slice0)    Executor memory: 90K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 3.961 ms
(14 rows)

-- built index for dist_small_2 and dist_large_2,
-- rerun queries that didn't choose the join below union all alternative
create index dist_small_2_index on dist_small_2 using btree (c1);
create index dist_large_2_index on dist_large_2 using btree (c1);
-- union of small tables
-- join below union all alternative chosen
-- Intuition: Compared to the same query before index was built for
-- dist_small_2, ORCA's cost model chooses to push join below union
-- all because this allows both union all children to benefit from 
-- indexed nested loop join (instead of just one child of the two).
explain analyze select c1 from dist_view_small join inner_1 on c1 = cc;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..54.62 rows=11 width=4) (actual time=3.429..3.429 rows=0 loops=1)
   ->  Hash Join  (cost=1.01..54.62 rows=4 width=4) (never executed)
         Hash Cond: (dist_small_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..26.00 rows=667 width=4) (actual time=0.008..0.008 rows=1 loops=1)
               ->  Seq Scan on dist_small_1  (cost=0.00..13.00 rows=334 width=4) (actual time=0.008..0.008 rows=1 loops=1)
               ->  Seq Scan on dist_small_2  (cost=0.00..13.00 rows=334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.378 ms
   (slice0)    Executor memory: 90K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 4.612 ms
(14 rows)

-- union all of large tables, one with a filter
-- join below union all alternative chosen
-- Intuition: Similarly, compared to the same query before index 
-- was built for dist_large_2, ORCA's cost model chooses to push
-- join below union all because this allows both union all children
-- to benefit from indexed nested loop join.
explain analyze select c1 from dist_view_large_filter join inner_1 on c1 = cc;
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=1.01..5987.62 rows=191 width=4) (actual time=4.296..4.296 rows=0 loops=1)
   ->  Hash Join  (cost=1.01..5987.62 rows=64 width=4) (never executed)
         Hash Cond: (dist_large_1.c1 = inner_1.cc)
         ->  Append  (cost=0.00..3372.09 rows=63337 width=4) (actual time=0.019..0.019 rows=1 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1361.00 rows=30003 width=4) (actual time=0.019..0.019 rows=1 loops=1)
                     Filter: (c1 < 90000)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (never executed)
         ->  Hash  (cost=1.00..1.00 rows=1 width=4) (never executed)
               ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.716 ms
   (slice0)    Executor memory: 123K bytes.
   (slice1)    Executor memory: 4170K bytes avg x 3 workers, 4170K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 5.223 ms
(15 rows)

-- subquery: aggregation of join, inequality predicate
-- join below union all alternative chosen
-- Intuition: This test is so constructed to have a deep (aggregation of join)
-- yet small (deduplicated) inner child. Making it deep is to verify the inner
-- child gets correctly "cloned" with all the columns correctly remapped when 
-- join is pushed below union all. Making it small is to not induce a high cost
-- of scanning it twice, which is necessary in pushing join below union all.
-- The inequality predicate is to rule out the option of hash join, so that
-- the join is more likely to be pushed down union all to leverage indexed nested
-- loop joins.
explain analyze select c1 from dist_view_large join
 (select distinct inner_2.cc from inner_1 join inner_2 on inner_1.cc = inner_2.cc) as inline on c1 < cc;
                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice4; segments: 3)  (cost=10000000004.35..10000028226.57 rows=200000 width=4) (actual time=36.046..36.046 rows=0 loops=1)
   ->  Nested Loop  (cost=10000000004.35..10000028226.57 rows=66667 width=4) (never executed)
         Join Filter: (dist_large_1.c1 < inner_2.cc)
         ->  Append  (cost=0.00..2222.00 rows=66667 width=4) (actual time=0.017..14.642 rows=66924 loops=1)
               ->  Seq Scan on dist_large_1  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.017..4.307 rows=33462 loops=1)
               ->  Seq Scan on dist_large_2  (cost=0.00..1111.00 rows=33334 width=4) (actual time=0.012..3.861 rows=33462 loops=1)
         ->  Materialize  (cost=4.35..4.58 rows=3 width=4) (never executed)
               ->  Broadcast Motion 3:3  (slice3; segments: 3)  (cost=4.35..4.53 rows=3 width=4) (never executed)
                     ->  HashAggregate  (cost=4.35..4.38 rows=1 width=4) (never executed)
                           Group Key: inner_2.cc
                           ->  Redistribute Motion 3:3  (slice2; segments: 3)  (cost=4.26..4.32 rows=1 width=4) (never executed)
                                 Hash Key: inner_2.cc
                                 ->  HashAggregate  (cost=4.26..4.26 rows=1 width=4) (never executed)
                                       Group Key: inner_2.cc
                                       ->  Hash Join  (cost=1.08..4.25 rows=2 width=4) (never executed)
                                             Hash Cond: (inner_2.cc = inner_1.cc)
                                             ->  Seq Scan on inner_2  (cost=0.00..3.10 rows=4 width=4) (never executed)
                                             ->  Hash  (cost=1.04..1.04 rows=1 width=4) (never executed)
                                                   ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                                                         ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 1.645 ms
   (slice0)    Executor memory: 156K bytes.
   (slice1)    Executor memory: 60K bytes avg x 3 workers, 60K bytes max (seg0).
   (slice2)    Executor memory: 2144K bytes avg x 3 workers, 2144K bytes max (seg0).
   (slice3)    Executor memory: 47K bytes avg x 3 workers, 47K bytes max (seg0).
   (slice4)    Executor memory: 96K bytes avg x 3 workers, 96K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 54.990 ms
(29 rows)

-- inequality join predicate 
-- union all of small tables
-- join below union all alternative chosen
-- Intuition: This test is to verify the type cast in the join predicate gets
-- correctly remapped when the join is pushed down union all. 
explain analyze select c1 from char_view_small join inner_3 on c1 < cc;
                                                                 QUERY PLAN                                                                 
--------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=10000000000.00..10000000073.05 rows=367 width=5) (actual time=2.758..2.758 rows=0 loops=1)
   ->  Nested Loop  (cost=10000000000.00..10000000073.05 rows=123 width=5) (never executed)
         Join Filter: (char_small_1.c1 < (inner_3.cc)::bpchar)
         ->  Append  (cost=0.00..17.00 rows=367 width=5) (actual time=0.008..0.126 rows=373 loops=1)
               ->  Seq Scan on char_small_1  (cost=0.00..13.00 rows=334 width=5) (actual time=0.008..0.088 rows=340 loops=1)
               ->  Seq Scan on char_small_2  (cost=0.00..4.00 rows=34 width=4) (actual time=0.026..0.031 rows=34 loops=1)
         ->  Materialize  (cost=0.00..1.05 rows=1 width=32) (never executed)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=32) (never executed)
                     ->  Seq Scan on inner_3  (cost=0.00..1.00 rows=1 width=32) (never executed)
 Planning time: 1.317 ms
   (slice0)    Executor memory: 123K bytes.
   (slice1)    Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 92K bytes avg x 3 workers, 92K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 4.090 ms
(16 rows)

-- union all of partition, distributed, and randomly distributed tables
-- join below union all alternative generated, but not chosen
explain analyze select c2 from part_dist_rand join inner_1 on c2 = cc;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=1.08..7465.08 rows=300 width=4) (actual time=4.643..4.643 rows=0 loops=1)
   ->  Hash Join  (cost=1.08..7465.08 rows=100 width=4) (never executed)
         Hash Cond: (part_dist_rand.c2 = inner_1.cc)
         ->  Subquery Scan on part_dist_rand  (cost=0.00..6336.00 rows=100000 width=4) (never executed)
               ->  Append  (cost=0.00..3336.00 rows=100000 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part1  (cost=0.00..445.00 rows=13334 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part2  (cost=0.00..335.00 rows=10000 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part3  (cost=0.00..334.00 rows=10000 width=8) (never executed)
                     ->  Seq Scan on dist  (cost=0.00..1111.00 rows=33334 width=8) (never executed)
                     ->  Seq Scan on rand  (cost=0.00..1111.00 rows=33334 width=8) (never executed)
         ->  Hash  (cost=1.04..1.04 rows=1 width=4) (never executed)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                     ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 3.983 ms
   (slice0)    Executor memory: 156K bytes.
   (slice1)    Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 4236K bytes avg x 3 workers, 4236K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 6.501 ms
(20 rows)

-- union all of partition and distributed tables
-- join below union all alternative chosen
explain analyze select c2 from part_dist join inner_1 on c2 = cc;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=1.08..4978.08 rows=200 width=4) (actual time=5.549..5.549 rows=0 loops=1)
   ->  Hash Join  (cost=1.08..4978.08 rows=67 width=4) (never executed)
         Hash Cond: (part_dist.c2 = inner_1.cc)
         ->  Subquery Scan on part_dist  (cost=0.00..4225.00 rows=66667 width=4) (never executed)
               ->  Append  (cost=0.00..2225.00 rows=66667 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part1  (cost=0.00..445.00 rows=13334 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part2  (cost=0.00..335.00 rows=10000 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part3  (cost=0.00..334.00 rows=10000 width=8) (never executed)
                     ->  Seq Scan on dist  (cost=0.00..1111.00 rows=33334 width=8) (never executed)
         ->  Hash  (cost=1.04..1.04 rows=1 width=4) (never executed)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                     ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 2.465 ms
   (slice0)    Executor memory: 156K bytes.
   (slice1)    Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 4236K bytes avg x 3 workers, 4236K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 7.875 ms
(19 rows)

-- union all of partition and distributed tables
-- both union all children have multiple filters
-- join below union all alternative chosen
explain analyze select c2 from part_dist_filter join inner_1 on c2 < cc;
                                                                 QUERY PLAN                                                                  
---------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=10000000000.00..10000003451.03 rows=3180 width=4) (actual time=9.849..9.849 rows=0 loops=1)
   ->  Nested Loop  (cost=10000000000.00..10000003451.03 rows=1060 width=4) (never executed)
         Join Filter: (part_1_prt_part1.c2 < inner_1.cc)
         ->  Append  (cost=0.00..2972.98 rows=3180 width=8) (actual time=0.021..7.612 rows=14 loops=1)
               ->  Append  (cost=0.00..1739.00 rows=18 width=8) (actual time=0.019..5.830 rows=14 loops=1)
                     ->  Seq Scan on part_1_prt_part1  (cost=0.00..695.00 rows=7 width=8) (actual time=0.019..2.341 rows=5 loops=1)
                           Filter: ((c1 < 100) AND (c2 = ANY ('{1,5,8}'::integer[])))
                     ->  Seq Scan on part_1_prt_part2  (cost=0.00..522.50 rows=6 width=8) (actual time=0.016..1.891 rows=4 loops=1)
                           Filter: ((c1 < 100) AND (c2 = ANY ('{1,5,8}'::integer[])))
                     ->  Seq Scan on part_1_prt_part3  (cost=0.00..521.50 rows=6 width=8) (actual time=0.016..1.747 rows=6 loops=1)
                           Filter: ((c1 < 100) AND (c2 = ANY ('{1,5,8}'::integer[])))
               ->  Bitmap Heap Scan on dist  (cost=877.55..1138.59 rows=3163 width=8) (never executed)
                     Recheck Cond: (c2 > 90000)
                     Filter: (c1 < 90000)
                     ->  Bitmap Index Scan on dist_index  (cost=0.00..875.18 rows=3335 width=0) (actual time=0.785..0.785 rows=3363 loops=1)
                           Index Cond: (c2 > 90000)
         ->  Materialize  (cost=0.00..1.05 rows=1 width=4) (never executed)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                     ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 3.805 ms
   (slice0)    Executor memory: 284K bytes.
   (slice1)    Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 837K bytes avg x 3 workers, 837K bytes max (seg0).  Work_mem: 41K bytes max.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 12.355 ms
(26 rows)

-- union all of partition and randomly distributed tables
-- join below union all alternative chosen
explain analyze select c2 from part_rand join inner_1 on c2 = cc;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=1.08..4978.08 rows=200 width=4) (actual time=3.970..3.970 rows=0 loops=1)
   ->  Hash Join  (cost=1.08..4978.08 rows=67 width=4) (never executed)
         Hash Cond: (part_rand.c2 = inner_1.cc)
         ->  Subquery Scan on part_rand  (cost=0.00..4225.00 rows=66667 width=4) (never executed)
               ->  Append  (cost=0.00..2225.00 rows=66667 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part1  (cost=0.00..445.00 rows=13334 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part2  (cost=0.00..335.00 rows=10000 width=8) (never executed)
                     ->  Seq Scan on part_1_prt_part3  (cost=0.00..334.00 rows=10000 width=8) (never executed)
                     ->  Seq Scan on rand  (cost=0.00..1111.00 rows=33334 width=8) (never executed)
         ->  Hash  (cost=1.04..1.04 rows=1 width=4) (never executed)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..1.04 rows=1 width=4) (never executed)
                     ->  Seq Scan on inner_1  (cost=0.00..1.00 rows=1 width=4) (never executed)
 Planning time: 2.433 ms
   (slice0)    Executor memory: 156K bytes.
   (slice1)    Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 4236K bytes avg x 3 workers, 4236K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 6.007 ms
(19 rows)

-- union all of partition, distributed, and randomly distributed tables
-- join below union all alternative generated, but not chosen
explain analyze select c2 from part_dist_rand join inner_2 on c2 = cc;
                                                                 QUERY PLAN                                                                  
---------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=3.88..8244.88 rows=3000 width=4) (actual time=3.478..236.649 rows=90020 loops=1)
   ->  Hash Join  (cost=3.88..8244.88 rows=1000 width=4) (actual time=0.738..228.470 rows=30145 loops=1)
         Hash Cond: (part_dist_rand.c2 = inner_2.cc)
         Extra Text: (seg0)   Hash chain length 1.0 avg, 1 max, using 10 of 524288 buckets.
         ->  Subquery Scan on part_dist_rand  (cost=0.00..6336.00 rows=100000 width=4) (actual time=0.017..133.132 rows=100118 loops=1)
               ->  Append  (cost=0.00..3336.00 rows=100000 width=8) (actual time=0.016..100.669 rows=100118 loops=1)
                     ->  Seq Scan on part_1_prt_part1  (cost=0.00..445.00 rows=13334 width=8) (actual time=0.018..1.883 rows=13437 loops=1)
                     ->  Seq Scan on part_1_prt_part2  (cost=0.00..335.00 rows=10000 width=8) (actual time=0.013..1.594 rows=10045 loops=1)
                     ->  Seq Scan on part_1_prt_part3  (cost=0.00..334.00 rows=10000 width=8) (actual time=0.014..1.355 rows=10036 loops=1)
                     ->  Seq Scan on dist  (cost=0.00..1111.00 rows=33334 width=8) (actual time=0.015..5.698 rows=33462 loops=1)
                     ->  Seq Scan on rand  (cost=0.00..1111.00 rows=33334 width=8) (actual time=0.019..49.331 rows=33464 loops=1)
         ->  Hash  (cost=3.50..3.50 rows=10 width=4) (actual time=0.022..0.022 rows=10 loops=1)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..3.50 rows=10 width=4) (actual time=0.006..0.014 rows=10 loops=1)
                     ->  Seq Scan on inner_2  (cost=0.00..3.10 rows=4 width=4) (actual time=0.022..0.042 rows=5 loops=1)
 Planning time: 2.687 ms
   (slice0)    Executor memory: 247K bytes.
   (slice1)    Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 4256K bytes avg x 3 workers, 4256K bytes max (seg0).  Work_mem: 1K bytes max.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 244.139 ms
(21 rows)

-- union all of partition and distributed tables
-- join below union all alternative generated, but not chosen
explain analyze select c2 from part_dist join inner_2 on c2 = cc;
                                                                 QUERY PLAN                                                                  
---------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=3.88..5498.88 rows=2000 width=4) (actual time=3.335..125.235 rows=90010 loops=1)
   ->  Hash Join  (cost=3.88..5498.88 rows=667 width=4) (actual time=0.607..116.699 rows=30143 loops=1)
         Hash Cond: (part_dist.c2 = inner_2.cc)
         Extra Text: (seg0)   Hash chain length 1.0 avg, 1 max, using 10 of 524288 buckets.
         ->  Subquery Scan on part_dist  (cost=0.00..4225.00 rows=66667 width=4) (actual time=0.022..59.151 rows=66924 loops=1)
               ->  Append  (cost=0.00..2225.00 rows=66667 width=8) (actual time=0.020..41.228 rows=66924 loops=1)
                     ->  Seq Scan on part_1_prt_part1  (cost=0.00..445.00 rows=13334 width=8) (actual time=0.020..2.207 rows=13437 loops=1)
                     ->  Seq Scan on part_1_prt_part2  (cost=0.00..335.00 rows=10000 width=8) (actual time=0.016..1.373 rows=10045 loops=1)
                     ->  Seq Scan on part_1_prt_part3  (cost=0.00..334.00 rows=10000 width=8) (actual time=0.014..1.329 rows=10036 loops=1)
                     ->  Seq Scan on dist  (cost=0.00..1111.00 rows=33334 width=8) (actual time=0.015..5.379 rows=33462 loops=1)
         ->  Hash  (cost=3.50..3.50 rows=10 width=4) (actual time=0.024..0.024 rows=10 loops=1)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..3.50 rows=10 width=4) (actual time=0.006..0.015 rows=10 loops=1)
                     ->  Seq Scan on inner_2  (cost=0.00..3.10 rows=4 width=4) (actual time=0.005..0.008 rows=5 loops=1)
 Planning time: 3.536 ms
   (slice0)    Executor memory: 247K bytes.
   (slice1)    Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 4256K bytes avg x 3 workers, 4256K bytes max (seg0).  Work_mem: 1K bytes max.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 133.231 ms
(20 rows)

-- union all of partition and randomly distributed tables
-- join below union all alternative generated, but not chosen
explain analyze select c2 from part_rand join inner_2 on c2 = cc;
                                                                 QUERY PLAN                                                                  
---------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)  (cost=3.88..5498.88 rows=2000 width=4) (actual time=3.443..120.409 rows=90010 loops=1)
   ->  Hash Join  (cost=3.88..5498.88 rows=667 width=4) (actual time=0.688..77.148 rows=30140 loops=1)
         Hash Cond: (part_rand.c2 = inner_2.cc)
         Extra Text: (seg0)   Hash chain length 1.0 avg, 1 max, using 10 of 524288 buckets.
         ->  Subquery Scan on part_rand  (cost=0.00..4225.00 rows=66667 width=4) (actual time=0.023..53.013 rows=66791 loops=1)
               ->  Append  (cost=0.00..2225.00 rows=66667 width=8) (actual time=0.021..22.685 rows=66791 loops=1)
                     ->  Seq Scan on part_1_prt_part1  (cost=0.00..445.00 rows=13334 width=8) (actual time=0.020..2.043 rows=13437 loops=1)
                     ->  Seq Scan on part_1_prt_part2  (cost=0.00..335.00 rows=10000 width=8) (actual time=0.015..1.399 rows=10045 loops=1)
                     ->  Seq Scan on part_1_prt_part3  (cost=0.00..334.00 rows=10000 width=8) (actual time=0.016..1.300 rows=10036 loops=1)
                     ->  Seq Scan on rand  (cost=0.00..1111.00 rows=33334 width=8) (actual time=0.011..10.559 rows=33464 loops=1)
         ->  Hash  (cost=3.50..3.50 rows=10 width=4) (actual time=0.137..0.137 rows=10 loops=1)
               ->  Broadcast Motion 3:3  (slice1; segments: 3)  (cost=0.00..3.50 rows=10 width=4) (actual time=0.006..0.127 rows=10 loops=1)
                     ->  Seq Scan on inner_2  (cost=0.00..3.10 rows=4 width=4) (actual time=0.004..0.004 rows=5 loops=1)
 Planning time: 3.565 ms
   (slice0)    Executor memory: 247K bytes.
   (slice1)    Executor memory: 58K bytes avg x 3 workers, 58K bytes max (seg0).
   (slice2)    Executor memory: 4256K bytes avg x 3 workers, 4256K bytes max (seg0).  Work_mem: 1K bytes max.
 Memory used:  128000kB
 Optimizer: Postgres query optimizer
 Execution time: 128.897 ms
(20 rows)

